version: '3.8'

# Docker Compose configuration following official Docker compose-for-agents patterns
# Based on: https://github.com/docker/compose-for-agents

# Models section - Define AI models using Docker Model Runner
models:
  gpt-oss:
    provider:
      type: model
    model: ai/gpt-oss
    context_size: 128000
    
  # Optional: Smaller model for faster responses  
  smollm2:
    provider:
      type: model
    model: ai/smollm2
    context_size: 8192

services:
  # Main AI Agent Service
  ai-agent:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - MODEL_URL=http://host.docker.internal:12434/engines/llama.cpp/v1
      - MODEL_NAME=ai/gpt-oss
      - REASONING_LEVEL=medium
      - PYTHONUNBUFFERED=1
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Multi-Agent Orchestrator (CrewAI style)
  crew-orchestrator:
    build:
      context: ./crew-ai
      dockerfile: Dockerfile
    environment:
      - MODEL_URL=http://host.docker.internal:12434/engines/llama.cpp/v1
      - MODEL_NAME=ai/gpt-oss
      - MCP_GATEWAY_URL=http://mcp-gateway:3000
    ports:
      - "8001:8000"
    volumes:
      - ./crew-ai/config:/app/config
    restart: unless-stopped

  # MCP Gateway for tool integration
  # Model Context Protocol gateway for secure tool access
  mcp-gateway:
    image: docker/mcp-gateway:latest
    ports:
      - "3000:3000"
    environment:
      - MCP_CONFIG_FILE=/config/mcp-config.json
    volumes:
      - ./mcp-config:/config
    restart: unless-stopped

  # Vector Database for RAG capabilities
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8002:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_HOST=0.0.0.0
      - CHROMA_PORT=8000
      - CHROMA_DB_IMPL=duckdb+parquet
      - CHROMA_PERSIST_DIRECTORY=/chroma/chroma
    restart: unless-stopped

  # Redis for agent memory and caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

  # Web UI for agent interaction
  web-ui:
    build:
      context: ./web-ui
      dockerfile: Dockerfile
    depends_on:
      - ai-agent
      - crew-orchestrator
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_CREW_API_URL=http://localhost:8001
    ports:
      - "3001:3000"
    restart: unless-stopped

# Networks
networks:
  default:
    name: ai-agent-network
    driver: bridge

# Volumes for data persistence
volumes:
  chroma_data:
    driver: local
  redis_data:
    driver: local

# Development override for local testing
# Usage: docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
